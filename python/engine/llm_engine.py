import json
import time
import re
import colorama
import ollama
import threading

from python.chat_manager import ChatManager
from python.engine.dynamic_db_engine import DynamicDBEngine
from python.engine.vision_pro import Vision_Pro
from python.engine.music_engine import MusicEngine
from python.engine.weather_system import Wheather_Engine
from python.identity_manager import IdentityManager


class LLM_Engine:
    def __init__(self, music_engine=None, vision_engine=None):
        # Sarah System Prompt (Strict Language Enforcer)
        print(colorama.Fore.YELLOW + "[STT] Initializing Whisper Model...")

        # Use provided music engine
        if music_engine:
            self.music = music_engine
        else:
            self.music = MusicEngine()

        # REUSE the vision engine passed from Main
        if vision_engine:
            self.vision = vision_engine
        else:
            self.vision = Vision_Pro()

        self.weather = Wheather_Engine()
        self.dynamicDb = DynamicDBEngine()
        self.chat_db = ChatManager()
        self.current_session_id = self.chat_db.create_session(title="Coding Session")
        self.id_manager = IdentityManager(self.dynamicDb)
        self.active_context = ""
        self.current_user = "Unknown"

        system_instructions = """
                You are Sarah, a witty conversational AI. 

                STRICT RULES:
                1. LANGUAGE: Speak ONLY in English or Hindi (Hinglish).
                2. NO HALLUCINATIONS: If input is gibberish, say "Can you repeat that?".
                3. FORMAT: Break responses into short, punchy sentences. Use new lines for pauses.
                4. Do NOT start sentences with "The user said" or "You said".
                5. Do not output long paragraphs.
                """

        self.history = [
            {"role": "system", "content": system_instructions}
        ]
        start_time = time.time()
        print(colorama.Fore.GREEN + f"[STT] Model loaded in {time.time() - start_time:.2f} seconds")

    def run_agentic_llm(self, text):
        # 1. PRE-PROCESSING
        text = text.lower().replace("pre-edarsion", "priyadarshan").replace("predation", "priyadarshan")

        # --- INJECT VISION CONTEXT ---
        visual_user = self.get_active_context()
        vision_info_str = ""

        if visual_user and visual_user not in ["unknown", "camera error", "none"]:
            if self.id_manager.current_user.lower() != visual_user:
                print(f"üëÄ Vision Override: Switching ID Manager to {visual_user}")
                self.id_manager.switch_user(visual_user)

            user_mem = self.dynamicDb.find_user(visual_user)
            vision_info_str = f"VISUAL REALITY: I can currently see '{visual_user}' in front of me. Memory: {user_mem}"

        elif visual_user == "unknown":
            vision_info_str = "VISUAL REALITY: I see a person in front of me, but I do not recognize them."
        else:
            vision_info_str = "VISUAL REALITY: No one is clearly visible to the camera."

        # User Change Detection
        new_user = self.id_manager.detect_user_change(text)
        if new_user:
            past_info = self.id_manager.switch_user(new_user)
            if past_info:
                self.active_context = f"You are talking to {new_user}. Memory: {past_info}"
                return f"Hello {new_user}! Long time no see. I remember {past_info}"
            else:
                self.active_context = f"You are talking to {new_user}. (New User)"
                return f"Hello {new_user}! Nice to meet you. I will remember you now."

        self.id_manager.add_to_buffer(text)

        # Check for music stop
        if "stop" in text and ("music" in text or "song" in text):
            self.music.stop()
            return "Stopping the music."

        tools_desc = """
            Available Tools:
            - Weather: 'Call : Weather <Location>'
            - Music: 'Call : Music <Song Name>'
            - Search: 'Call : Search <Query>' (Use this for 'Who is X', 'Developer', 'Creator')
            - Vision: 'Call : Vision <Query>' (Use for 'What do you see?', 'Who is this?')
            - Add to DB: 'Call : Add <Name> <Info>'
            - Update DB: 'Call : Update <Name> <Info>'
            - Final Answer: 'Final Answer : <Reply>'
            """

        system_context = f"""
            You are Sarah. Your Creator is 'Priyadarshan'.  
            {vision_info_str}

            TOOL USAGE GUIDELINES (STRICT):
            1. VISUAL AWARENESS: Use the 'VISUAL REALITY' data above. If it says you see someone (e.g., '{visual_user}'), ACKNOWLEDGE THEM. Do not say "I don't see anyone".
            2. VISION TOOL: Use 'Call : Vision check' if user asks "What do you see?" or "Who am I?".
            3. SEARCH: Use 'Call : Search <query>' ONLY if the user asks "Who is X?" or "What do you know about X?".
            4. ADD (MEMORY): Use 'Call : Add <name> <info>' ONLY when the user EXPLICITLY asks to "remember", "save", "register", or "add" a person.
            5. UPDATE: Use 'Call : Update <name> <info>' only for correcting existing info.
            6. MUSIC: Use 'Call : Music <song>' for playback.
            7. WEATHER: Use 'Call : Weather <city>' for forecasts.

            CRITICAL FALLBACK (General Knowledge):
            If the user asks a general question or simply wants to chat, DO NOT CALL ANY TOOL. 
            Instead, output: 'Final Answer : <Your direct answer here>'.
            """

        prompt = f"{system_context}\n{tools_desc}\nUser asked: \"{text}\"\nDECIDE TOOL. OUTPUT FORMAT ONLY."

        print(f"ü§ñ Agent Thinking (Vision Aware)...")

        try:
            raw_response = ollama.generate(model='qwen2.5:3b-instruct', prompt=prompt, options={'temperature': 0.1})
            response = raw_response['response'].strip()
            print(f"ü§ñ Agent Output: {response}")

            match = re.search(r"Call\s*:\s*(\w+)\s+(.*)", response, re.IGNORECASE)

            if match:
                tool_name = match.group(1).lower()
                argument = match.group(2).strip()

                # --- 1. VISION TOOL (Added Logic) ---
                if tool_name == "vision":
                    # Use the visual_user variable we already calculated
                    if visual_user and visual_user not in ["unknown", "camera error", "none"]:
                        return f"I can see {visual_user} standing right in front of me."
                    elif visual_user == "unknown":
                        return "I can see someone, but I don't recognize them."
                    else:
                        return "I don't see anyone right now."

                elif tool_name == "weather":
                    print(f"üîç Fetching weather data for: {argument}...")
                    data = self.weather.get_weather(argument)
                    make_response = self.build_response(text, data)
                    return make_response

                elif tool_name == "add":
                    json_info = self.extract_parameters(text)
                    if json_info and "name" in json_info:
                        extracted_name = json_info["name"].strip()
                        extracted_info = json_info.get("info", "")

                        forbidden_names = ["sarah", "i", "me", "myself", "person", "someone", "unknown", "nobody",
                                           "user"]
                        if extracted_name.lower() in forbidden_names or len(extracted_name) < 3:
                            print(f"üö´ Blocked Garbage Add Request: {extracted_name}")
                            return "I'm not sure who you want me to remember. Can you say the name clearly?"

                        print(f"üöÄ Triggering Registration for: {extracted_name}")
                        return f"[REGISTER] {extracted_name} | {extracted_info}"
                    else:
                        return "I couldn't understand who to add."

                elif tool_name == "update":
                    json_info = self.extract_parameters(text)
                    if json_info and "name" in json_info:
                        extracted_name = json_info["name"]
                        extracted_info = json_info["info"]
                        print(f"üîÑ Updating: {extracted_name} -> {extracted_info}")
                        self.dynamicDb.update_user(extracted_name, extracted_info)
                        return f"Updated information for {extracted_name}."
                    else:
                        return "Could not extract details for update."

                elif tool_name == "music":
                    ctx = self.build_response(text, None)

                    def play_music_worker():
                        print(f"üéµ Thread fetching: {argument}")
                        try:
                            self.music.play(argument)
                        except Exception as e:
                            print(f"Music Error: {e}")

                    music_thread = threading.Thread(target=play_music_worker)
                    music_thread.daemon = True
                    music_thread.start()
                    return f"Starting music: {ctx}"

                elif tool_name == "search":
                    if any(x in argument.lower() for x in ["developer", "creator", "maker"]):
                        argument = "priyadarshan"
                    print(f"üîç Searching DB for: {argument}")
                    data = self.dynamicDb.find_user(argument)
                    if data:
                        return self.generate_info(str(data), argument)
                    else:
                        print(f"‚ö†Ô∏è DB Miss. Switching to General Knowledge.")
                        return self.chat(text)

            if "final answer" in response.lower():
                try:
                    return response.split(":", 1)[1].strip()
                except:
                    return response

            # If no tool matched, just chat
            return self.chat(text)

        except Exception as e:
            print(f"‚ùå Agent Error: {e}")
            # Fallback to chat to prevent silence
            return self.chat(text)

    # --- MISSING FUNCTIONS RESTORED BELOW ---

    def get_active_context(self):
        """
        Checks who is currently in front of the camera.
        Removes trailing numbers (e.g. 'Priyadarshan7' -> 'Priyadarshan')
        """
        detected_names = self.vision.scan_scene()

        # Debugging ke liye print (Optional)
        # print(f"üëÄ Vision Saw: {detected_names}")

        if detected_names:
            # 1. Unknown aur Error hatao
            known_faces = [name for name in detected_names if name != "Unknown" and name != "Camera Error"]

            if known_faces:
                raw_name = known_faces[0]  # Jaise: "Priyadarshan7"

                # --- üî• MAGIC LOGIC HERE üî• ---
                # String ke end se 0-9 tak saare digits uda do
                clean_name = raw_name.rstrip("0123456789")

                # Agar galti se pura naam hi number tha (kam chance hai), to wapas raw rakh lo
                if len(clean_name) > 0:
                    self.current_user = clean_name
                else:
                    self.current_user = raw_name

            elif "Unknown" in detected_names:
                self.current_user = "Unknown"

        # Agar koi nahi dikha to purana user hi rahega
        return self.current_user.lower()

    def extract_parameters(self, text):
        prompt = f"""
        Extract the 'name' and 'info' from the following user command.
        Command: "{text}"
        Return ONLY a JSON object. Format: {{"name": "Person Name", "info": "The information"}}
        """
        try:
            raw = ollama.generate(model='qwen2.5:3b-instruct', prompt=prompt, options={'temperature': 0.0})
            response_text = raw['response'].strip().replace("```json", "").replace("```", "").strip()
            return json.loads(response_text)
        except Exception as e:
            print(f"‚ùå Extraction Error: {e}")
            return None

    def chat(self, user_input):
        # 1. Update history
        self.history.append({"role": "user", "content": user_input})

        # 2. Get Response
        try:
            response = ollama.chat(model='qwen2.5:3b-instruct', messages=self.history)
            reply = response['message']['content']
        except Exception as e:
            print(f"Chat Gen Error: {e}")
            reply = "I'm having trouble thinking right now."

        # 3. Save to history
        self.history.append({"role": "assistant", "content": reply})
        self.chat_db.add_message(self.current_session_id, "user", user_input)
        self.chat_db.add_message(self.current_session_id, "assistant", reply)

        # 4. Background Fact Extraction
        save_thread = threading.Thread(target=self.save_to_memory, args=(user_input, self.current_user))
        save_thread.start()

        return reply

    def build_response(self, query, data):
        system_prompt = """
            You are Sarah. Convert the provided data into a natural, conversational response for the user.
            Keep it concise.
            """
        user_message = f"User Query: {query}\nData Found: {data}\nResponse:"

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]
        try:
            response = ollama.chat(model='qwen2.5:3b-instruct', messages=messages)
            return response['message']['content'].strip()
        except:
            return f"Here is the data: {data}"

    def generate_info(self, json_text, name):
        system_prompt = f"Describe {name} based on this data. Use 'He/She/They', not 'I'. Data: {json_text}"
        try:
            response = ollama.generate(model='qwen2.5:3b-instruct', prompt=system_prompt)
            return response['response'].strip()
        except:
            return f"I found info on {name}: {json_text}"

    def save_to_memory(self, text, user_name):
        if user_name in ["Unknown", "priyadarshan"]: return

        prompt = f"Extract facts about '{user_name}' from: \"{text}\". Return fact or 'None'."
        try:
            response = ollama.generate(model='qwen2.5:3b-instruct', prompt=prompt)
            fact = response['response'].strip()
            if "None" not in fact and len(fact) > 5:
                self.dynamicDb.add_person(user_name, fact)
                print(colorama.Fore.GREEN + f"üíæ Memory Updated for {user_name}: {fact}")
        except:
            pass